{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mzkrxoOpQU02",
        "outputId": "63d169da-c1bb-4760-f67b-6b13addcf4dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive, userdata\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/\n",
        "!git clone https://github.com/jiseshen/preference-tracing.git\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s6i3Ie3XQd-r",
        "outputId": "96937de1-1468-45cb-e9cf-fe146bcf5728"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive\n",
            "Cloning into 'preference-tracing'...\n",
            "remote: Enumerating objects: 127, done.\u001b[K\n",
            "remote: Counting objects: 100% (127/127), done.\u001b[K\n",
            "remote: Compressing objects: 100% (78/78), done.\u001b[K\n",
            "remote: Total 127 (delta 60), reused 112 (delta 45), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (127/127), 1.65 MiB | 4.20 MiB/s, done.\n",
            "Resolving deltas: 100% (60/60), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/preference-tracing/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U8fxJFINR3jR",
        "outputId": "20280dff-8f14-48a5-dfe4-e454170dcebc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/preference-tracing\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')\n",
        "os.environ[\"HF_TOKEN\"] = userdata.get(\"HF_TOKEN\")\n",
        "os.environ[\"HUGGINGFACE_HUB_TOKEN\"] = userdata.get(\"HF_TOKEN\")\n",
        "import huggingface_hub\n",
        "huggingface_hub.login(token=userdata.get(\"HF_TOKEN\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oULNVkjbRiKp",
        "outputId": "286a84aa-bf5e-41c7-c39e-10111c7bc3c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n",
            "WARNING:huggingface_hub._login:Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from preference_tracing import PreferenceTracing\n",
        "import json\n",
        "from preference_prompt import *\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "tDjyNqUbRz7y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for mode in [\"Trace\", \"CoT\", \"Hybrid\"]:\n",
        "\n",
        "    preference_tracing = PreferenceTracing(\n",
        "        online_prompt=online_prompt,\n",
        "        hypothesis_prompt=hypothesis_prompt,\n",
        "        rejuvenate_prompt=rejuvenate_prompt,\n",
        "        summary_prompt=summary_prompt,\n",
        "        CoT_prompt=CoT_prompt,\n",
        "        mode=mode,\n",
        "        base_model=\"gpt-4o-mini\",\n",
        "        temperature=0.2,\n",
        "        N=5,\n",
        "        uncertainty_threshold=0.45,\n",
        "    )\n",
        "\n",
        "    os.makedirs(\"log\", exist_ok=True)\n",
        "\n",
        "    with open(\"profiles_dataset.json\", \"r\") as f:\n",
        "        data = json.load(f)\n",
        "\n",
        "    reward_record = []\n",
        "    uncertainty_record = []\n",
        "    token_record = []\n",
        "\n",
        "    for user in tqdm(data[10:30]):\n",
        "        user[\"behavior\"] = user[\"behavior\"][:50]\n",
        "        preference_tracing.trace(user)\n",
        "        reward_record.append(preference_tracing.reward)\n",
        "        uncertainty_record.append(preference_tracing.avg_uncertainty)\n",
        "        token_record.append([preference_tracing.prompt_tokens, preference_tracing.completion_tokens])\n",
        "        with open(f\"log/{mode}_record.json\", \"w\") as f:\n",
        "            json.dump({\n",
        "                \"reward\": reward_record,\n",
        "                \"uncertainty\": uncertainty_record,\n",
        "                \"token\": token_record,\n",
        "            }, f)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pRKGUqxUWEtQ",
        "outputId": "7c83c317-d1ff-4edd-9725-4c45fab47b03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 25%|██▌       | 5/20 [57:50<2:53:30, 694.05s/it]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "index 5 is out of bounds for axis 0 with size 5",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-a2edf5a32409>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0muser\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0muser\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"behavior\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muser\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"behavior\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mpreference_tracing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0mreward_record\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreference_tracing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0muncertainty_record\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreference_tracing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mavg_uncertainty\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/MyDrive/preference-tracing/preference_tracing.py\u001b[0m in \u001b[0;36mtrace\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     57\u001b[0m                     \u001b[0;34m(\u001b[0m\u001b[0muncertainty\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mavg_uncertainty\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"CoT\"\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0muncertainty\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muncertainty_threshold\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m                 self.hypothesis_update(\n\u001b[0m\u001b[1;32m     60\u001b[0m                     Context=context, Preferred=preferred, Rejected=rejected)\n\u001b[1;32m     61\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary_hypotheses\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/MyDrive/preference-tracing/thought_tracing.py\u001b[0m in \u001b[0;36mhypothesis_update\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhypotheses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Likelihood\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0msumm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0msumm\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0msumm\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhypotheses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhypotheses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: index 5 is out of bounds for axis 0 with size 5"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "with open(\"log/Trace_record.json\", \"r\") as f:\n",
        "    Trace_record = json.load(f)\n",
        "\n",
        "with open(\"log/CoT_record.json\", \"r\") as f:\n",
        "    CoT_record = json.load(f)\n",
        "\n",
        "with open(\"log/Hybrid_record.json\", \"r\") as f:\n",
        "    Hybrid_record = json.load(f)\n",
        "\n",
        "cot_reward = np.array([record for record in CoT_record[\"reward\"]])\n",
        "hybrid_reward = np.array([record for record in Hybrid_record[\"reward\"]])\n",
        "trace_reward = np.array([record for record in Trace_record[\"reward\"]])\n",
        "\n",
        "plt.figure(figsize=(8, 5), dpi=150)\n",
        "\n",
        "plt.plot(trace_reward.mean(axis=0), label='Trace', linewidth=2, color='#1f77b4')\n",
        "plt.plot(cot_reward.mean(axis=0), label='CoT', linewidth=2, color='#ff7f0e')\n",
        "plt.plot(hybrid_reward.mean(axis=0), label='Hybrid', linewidth=2, color='#2ca02c')\n",
        "\n",
        "plt.xlabel('Timestep', fontsize=12)\n",
        "plt.ylabel('Reward', fontsize=12)\n",
        "plt.title('Reward throughout Trajectory', fontsize=14)\n",
        "plt.legend(fontsize=10)\n",
        "plt.grid(True, linestyle='--', alpha=0.5)\n",
        "plt.tight_layout()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "yvih6swPgQT4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cot_prompt_token = np.array([i[0] for i in CoT_record[\"token\"]])\n",
        "cot_response_token = np.array([i[1] for i in CoT_record[\"token\"]])\n",
        "hybrid_prompt_token = np.array([i[0] for i in Hybrid_record[\"token\"]])\n",
        "hybrid_response_token = np.array([i[1] for i in Hybrid_record[\"token\"]])\n",
        "trace_prompt_token = np.array([i[0] for i in Trace_record[\"token\"]])\n",
        "trace_response_token = np.array([i[1] for i in Trace_record[\"token\"]])\n",
        "\n",
        "cot_prompt_token = cot_prompt_token / np.array([len(i) for i in CoT_record[\"reward\"]], dtype=np.float32)[:, np.newaxis]\n",
        "cot_response_token = cot_response_token / np.array([len(i) for i in CoT_record[\"reward\"]], dtype=np.float32)[:, np.newaxis]\n",
        "hybrid_prompt_token = hybrid_prompt_token / np.array([len(i) for i in Hybrid_record[\"reward\"]], dtype=np.float32)[:, np.newaxis]\n",
        "hybrid_response_token = hybrid_response_token / np.array([len(i) for i in Hybrid_record[\"reward\"]], dtype=np.float32)[:, np.newaxis]\n",
        "trace_prompt_token = trace_prompt_token / np.array([len(i) for i in Trace_record[\"reward\"]], dtype=np.float32)[:, np.newaxis]\n",
        "trace_response_token = trace_response_token / np.array([len(i) for i in Trace_record[\"reward\"]], dtype=np.float32)[:, np.newaxis]\n",
        "\n",
        "cot_prompt_token = cot_prompt_token.mean()\n",
        "cot_response_token = cot_response_token.mean()\n",
        "hybrid_prompt_token = hybrid_prompt_token.mean()\n",
        "hybrid_response_token = hybrid_response_token.mean()\n",
        "trace_prompt_token = trace_prompt_token.mean()\n",
        "trace_response_token = trace_response_token.mean()\n",
        "\n",
        "categories = [\"Trace\", \"CoT\", \"Hybrid\"]\n",
        "\n",
        "x = np.arange(len(categories))\n",
        "bar_width = 0.35\n",
        "fig, ax = plt.subplots(figsize=(10, 6), dpi=150)\n",
        "\n",
        "rects1 = ax.bar(x - bar_width/2, [trace_prompt_token, cot_prompt_token, hybrid_prompt_token], bar_width, label='Prompt', color='#1f77b4')\n",
        "rects2 = ax.bar(x + bar_width/2, [trace_response_token, cot_response_token, hybrid_response_token], bar_width, label='Completion', color='#ff7f0e')\n",
        "\n",
        "ax.set_ylabel(\"Token Usage\")\n",
        "ax.set_title(\"Token Usage of Different Settings\")\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(categories)\n",
        "\n",
        "ax.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "109ttmhzAQXx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
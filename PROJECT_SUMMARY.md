# PRISM Preference Tracing - Complete System Documentation

## é¡¹ç›®æ¦‚è¿°

æœ¬é¡¹ç›®å°† thought-tracing æ¡†æ¶ï¼ˆç”¨äº Theory of Mind æ¨ç†ï¼‰æ”¹é€ ä¸ºç”¨æˆ·åå¥½åœ¨çº¿å­¦ä¹ ç³»ç»Ÿï¼Œåº”ç”¨äº PRISM pluralistic alignment æ•°æ®é›†ã€‚

### æ ¸å¿ƒåˆ›æ–°
- **ä» ToM åˆ°åå¥½å­¦ä¹ **: å°†"è¿½è¸ª agent å¿ƒç†çŠ¶æ€"è½¬æ¢ä¸º"è¿½è¸ªç”¨æˆ·åå¥½"
- **åœ¨çº¿å­¦ä¹ **: é€è½®å¯¹è¯æ›´æ–°ç”¨æˆ·ç”»åƒï¼Œæ— éœ€æ‰¹é‡è®­ç»ƒ
- **ä¸ç¡®å®šæ€§å»ºæ¨¡**: ç»´æŠ¤å¤šä¸ªå‡è®¾åŠå…¶æƒé‡ï¼Œé‡åŒ–ä¸ç¡®å®šæ€§
- **å¯è§£é‡Šæ€§**: æ¯ä¸ªå†³ç­–éƒ½å¯è¿½æº¯åˆ°å…·ä½“çš„åå¥½å‡è®¾

---

## æ–‡ä»¶æ¸…å•

### æ ¸å¿ƒä»£ç 
| æ–‡ä»¶ | åŠŸèƒ½ | è¡Œæ•° |
|------|------|------|
| `preference_tracer.py` | ä¸»è¦è¿½è¸ªå¼•æ“ | ~350 |
| `survey_evaluator.py` | é—®å·å¯¹é½è¯„ä¼° | ~150 |
| `visualize_results.py` | ç»“æœå¯è§†åŒ– | ~150 |
| `run_prism_pipeline.py` | ä¸»è¿è¡Œè„šæœ¬ | ~100 |
| `batch_runner.py` | æ‰¹é‡å®éªŒè¿è¡Œå™¨ | ~200 |

### æ–‡æ¡£
| æ–‡ä»¶ | å†…å®¹ |
|------|------|
| `PRISM_README.md` | å®Œæ•´è‹±æ–‡æ–‡æ¡£ |
| `QUICKSTART_CN.md` | å¿«é€Ÿå¼€å§‹æŒ‡å—ï¼ˆä¸­æ–‡ï¼‰ |
| `IMPLEMENTATION_SUMMARY.md` | å®ç°ç»†èŠ‚æ€»ç»“ |
| `PROJECT_SUMMARY.md` | æœ¬æ–‡æ¡£ |

### é…ç½®ä¸æµ‹è¯•
| æ–‡ä»¶ | åŠŸèƒ½ |
|------|------|
| `configs.yaml` | å®éªŒé…ç½®æ¨¡æ¿ |
| `requirements_prism.txt` | Python ä¾èµ– |
| `test_setup.py` | ç¯å¢ƒéªŒè¯è„šæœ¬ |

---

## Tracer è°ƒç”¨é€»è¾‘è¯¦è§£

### åŸå§‹ Tracer (thought-tracing/tracer.py)

```python
# 1. é¢„å¤„ç†è¾“å…¥ - è¯†åˆ«ç›®æ ‡ agent å’Œæ ‡æ³¨åŠ¨ä½œ
preprocessed = preprocess_input(text, target_agent)
trajectory = preprocessed['trajectory']  # state-action åºåˆ—
perceptions = preprocessed['perceptions']  # æ¯æ­¥çš„æ„ŸçŸ¥

# 2. é€æ­¥è¿½è¸ª
hypotheses_list = []
for state_action, perception in zip(trajectory, perceptions):
    if first_step:
        # åˆå§‹åŒ–: ç”Ÿæˆ n ä¸ªå…³äº agent ä¿¡å¿µçš„å‡è®¾
        hypotheses = initialize(state_action, perception)
    else:
        # ä¼ æ’­: åŸºäºæ–°è§‚å¯Ÿæ›´æ–°æ¯ä¸ªå‡è®¾
        hypotheses = propagate(existing_hypotheses, state_action, perception)
    
    if state_action['action']:
        # åŠ æƒ: åŸºäºåŠ¨ä½œå¯èƒ½æ€§è¯„ä¼°æ¯ä¸ªå‡è®¾
        weights = weigh(hypotheses, action, mode="prompting")
        hypotheses.update_weights(weights)
        
        # é‡é‡‡æ ·: å¦‚æœå‡è®¾é€€åŒ–ï¼ˆESS å¤ªä½ï¼‰
        ess = compute_ess(hypotheses)
        if ess < threshold:
            hypotheses = resample_hypotheses(hypotheses, ess)
    
    hypotheses_list.append(hypotheses)

# 3. æ±‡æ€»è¾“å‡º
traced_thoughts = chain_weighted_average_trace(hypotheses_list)
```

**å…³é”®æ–¹æ³•**:

1. **initialize()**: 
   - è¾“å…¥: state, action, perception
   - æç¤º: "ç”Ÿæˆ n ä¸ªå‡è®¾ï¼Œè§£é‡Š agent çš„è¡Œä¸º"
   - è¾“å‡º: n ä¸ªå‡åŒ€æƒé‡çš„å‡è®¾

2. **propagate()**:
   - è¾“å…¥: ç°æœ‰å‡è®¾ + æ–°è§‚å¯Ÿ
   - æç¤º: "ç»™å®šä¹‹å‰çš„å‡è®¾å’Œæ–°ä¿¡æ¯ï¼Œagent ç°åœ¨ç›¸ä¿¡ä»€ä¹ˆï¼Ÿ"
   - è¾“å‡º: æ¯ä¸ªå‡è®¾çš„æ›´æ–°ç‰ˆæœ¬

3. **weigh()**:
   - è¾“å…¥: å‡è®¾ + å®é™…è§‚å¯Ÿåˆ°çš„åŠ¨ä½œ
   - æç¤º: "ç»™å®šå‡è®¾ Hï¼Œagent æ‰§è¡ŒåŠ¨ä½œ A çš„å¯èƒ½æ€§ï¼Ÿ"
   - LLM å›ç­” 6 æ¡£é‡è¡¨ï¼Œæ˜ å°„åˆ°åˆ†æ•°ï¼Œsoftmax å½’ä¸€åŒ–

4. **resample()**:
   - è®¡ç®— ESS = 1 / Î£(w_iÂ²)
   - å¦‚æœ ESS < n/2ï¼ŒæŒ‰æƒé‡é‡é‡‡æ · n ä¸ªå‡è®¾
   - é‡ç½®æƒé‡ä¸ºå‡åŒ€åˆ†å¸ƒ

5. **chain_weighted_average_trace()**:
   - å¯¹æ¯ä¸€æ­¥ï¼Œç”¨æƒé‡å¹³å‡æ‰€æœ‰å‡è®¾
   - ç”Ÿæˆè¿è´¯çš„æ€ç»´é“¾å™è¿°

---

## PRISM Preference Tracer é€‚é…

### å…³é”®æ˜ å°„

| ç»´åº¦ | ToM Tracer | Preference Tracer |
|------|-----------|-------------------|
| **ç›®æ ‡** | Agent (æ•…äº‹ä¸­çš„è§’è‰²) | User (å¯¹è¯å‚ä¸è€…) |
| **çŠ¶æ€** | åœºæ™¯æè¿° | å¯¹è¯å†å² |
| **åŠ¨ä½œ** | Agent è¡Œä¸º | User é€‰æ‹©æŸä¸ªå›å¤ |
| **æ„ŸçŸ¥** | è§†è§‰ã€å¬è§‰ç­‰æ„Ÿå®˜ä¿¡æ¯ | å¯è§çš„å›å¤å€™é€‰ |
| **å‡è®¾** | Agent çš„ä¿¡å¿µã€æ„å›¾ | User çš„åå¥½ã€ä»·å€¼è§‚ |

### æ ¸å¿ƒæ–¹æ³•é€‚é…

#### 1. initialize_hypotheses()
```python
def initialize_hypotheses(self, user_id, conversation_history, candidates):
    # æ ¼å¼åŒ–è¾“å…¥
    history_str = format_conversation_history(conversation_history)
    candidates_str = format_candidates(candidates)
    
    # æ„é€ æç¤º
    prompt = f"""
    <conversation history>
    {history_str}
    </conversation history>
    
    <current responses>
    {candidates_str}
    </current responses>
    
    Generate {n_hypotheses} hypotheses about the user's preferences, 
    values, and communication style that would explain their response choice.
    """
    
    # ç”Ÿæˆå‡è®¾
    hypotheses_list = prompting_for_ordered_list(tracer_model, prompt, n_hypotheses)
    weights = uniform(n_hypotheses)
    
    return HypothesesSetV3(user_id, contexts, perceptions, hypotheses_list, weights)
```

**ç¤ºä¾‹è¾“å‡º**:
```
1. User prefers concise, direct responses without unnecessary elaboration
2. User values factual accuracy over politeness in technical discussions
3. User appreciates when AI acknowledges uncertainty rather than overconfident responses
4. User prefers responses that provide actionable next steps
```

#### 2. propagate_hypotheses()
```python
def propagate_hypotheses(self, existing_hypotheses, new_history, new_candidates):
    # å¯¹æ¯ä¸ªç°æœ‰å‡è®¾
    propagation_prompts = []
    for hypothesis in existing_hypotheses.texts:
        prompt = f"""
        <previous user preference hypothesis>
        {hypothesis}
        </previous user preference hypothesis>
        
        <new conversation context>
        {format_new_context(new_history, new_candidates)}
        </new conversation context>
        
        Question: Based on the previous hypothesis and new conversation context,
        what are the user's updated preferences and values? Provide a refined hypothesis.
        """
        propagation_prompts.append(prompt)
    
    # æ‰¹é‡å¤„ç†
    propagated_texts = tracer_model.batch_interact(propagation_prompts)
    
    return HypothesesSetV3(..., texts=propagated_texts, weights=existing_weights, 
                          parent_hypotheses=existing_hypotheses.hypotheses)
```

#### 3. weigh_hypotheses()
```python
def weigh_hypotheses(self, hypotheses, chosen_response, candidates):
    # æ„é€ è¯„ä¼°æç¤º
    likelihood_prompts = []
    for hypothesis in hypotheses.texts:
        prompt = f"""
        <user preference hypothesis>
        {hypothesis}
        </user preference hypothesis>
        
        <available responses>
        {format_candidates(candidates, include_chosen=True)}
        </available responses>
        
        <chosen response>
        {chosen_response['content']}
        </chosen response>
        
        Question: Given the user's preferences described in the hypothesis,
        how likely would they choose the response above?
        
        Options:
        (a) Very Likely (90%)
        (b) Likely (70%)
        (c) Somewhat Likely (50%)
        (d) Somewhat Unlikely (30%)
        (e) Unlikely (10%)
        (f) Very Unlikely (<5%)
        
        Briefly explain and then answer with one option.
        Answer:
        """
        likelihood_prompts.append(prompt)
    
    # æ‰¹é‡è¯„ä¼°
    raw_predictions = tracer_model.batch_interact(likelihood_prompts)
    
    # è§£æå’Œæ˜ å°„åˆ†æ•°
    score_mapping = {'a': 3, 'b': 2.5, 'c': 2, 'd': 1, 'e': 0.5, 'f': 0.001}
    raw_scores = [map_response_to_score(pred, score_mapping) for pred in raw_predictions]
    weights = softmax(raw_scores)
    
    return {'weights': weights, 'prompts': likelihood_prompts, 
            'raw_predictions': raw_predictions, 'raw_scores': raw_scores}
```

#### 4. summarize_hypotheses()
```python
def summarize_hypotheses(self, hypotheses):
    # åˆ—å‡ºåŠ æƒå‡è®¾
    weighted_list = "\n".join([
        f"- {text} (weight: {weight:.3f})"
        for text, weight in zip(hypotheses.texts, hypotheses.weights)
    ])
    
    prompt = f"""
    <weighted hypotheses about user preferences>
    {weighted_list}
    </weighted hypotheses about user preferences>
    
    Summarize these hypotheses into a coherent user preference profile.
    Focus on the most important preferences (higher weights) and synthesize
    overlapping themes. Provide a concise profile.
    """
    
    summary = tracer_model.interact(prompt, temperature=0, max_tokens=512)
    return summary
```

**ç¤ºä¾‹è¾“å‡º**:
```
This user demonstrates a clear preference for directness and efficiency in 
communication, valuing concise responses that get to the point quickly. They 
prioritize factual accuracy and appreciate when the AI acknowledges limitations
or uncertainty rather than providing overconfident answers. The user tends to
favor actionable advice and practical next steps over abstract explanations.
Their interaction style suggests they value their time and prefer responses
that respect this by being both informative and succinct.
```

#### 5. evaluate_generation()
```python
def evaluate_generation(self, user_profile, conversation_history, 
                       candidates, chosen_response):
    # 1. åŸºäºç”¨æˆ·ç”»åƒç”Ÿæˆå›å¤
    gen_prompt = f"""
    <user preference profile>
    {user_profile}
    </user preference profile>
    
    <conversation history>
    {format_conversation_history(conversation_history)}
    </conversation history>
    
    Based on the user's preferences, generate an appropriate response
    to their last message.
    """
    
    generated_response = tracer_model.interact(gen_prompt, temperature=0.7)
    
    # 2. è¯„ä¼°ä¸å®é™…é€‰æ‹©çš„ç›¸ä¼¼åº¦
    eval_prompt = f"""
    <generated response>
    {generated_response}
    </generated response>
    
    <actual chosen response>
    {chosen_response['content']}
    </actual chosen response>
    
    Rate how similar these responses are in style, content, and alignment
    with user preferences on a scale of 1-10.
    
    Rating:
    """
    
    rating_response = eval_model.interact(eval_prompt, temperature=0)
    rating = parse_rating(rating_response)  # æå–æ•°å€¼
    
    return rating / 10.0  # å½’ä¸€åŒ–åˆ° 0-1
```

#### 6. predict_choice()
```python
def predict_choice(self, user_profile, conversation_history, candidates):
    candidates_str = format_candidates(candidates, numbered=True)
    
    prompt = f"""
    <user preference profile>
    {user_profile}
    </user preference profile>
    
    <conversation history>
    {format_conversation_history(conversation_history)}
    </conversation history>
    
    <response candidates>
    {candidates_str}
    </response candidates>
    
    Based on the user's preferences, which response would they most likely
    choose? Answer with just the number (1-{len(candidates)}).
    
    Answer:
    """
    
    prediction = tracer_model.interact(prompt, temperature=0, max_tokens=10)
    predicted_idx = parse_index(prediction) - 1  # è½¬æ¢ä¸º 0-based index
    
    return predicted_idx
```

---

## å®Œæ•´è¿½è¸ªæµç¨‹

```python
def trace_user_preferences(self, user_conversations):
    user_id = user_conversations[0]['user_id']
    conversations = user_conversations[0]['conversation']
    
    # æŒ‰ turn åˆ†ç»„
    turns = group_by_turns(conversations)
    
    hypotheses = None
    turn_results = []
    
    for turn_idx, turn_data in enumerate(turns):
        # æå–å½“å‰è½®æ¬¡æ•°æ®
        user_msg = turn_data['user_message']
        candidates = turn_data['candidates']  # å¤šä¸ªæ¨¡å‹å›å¤
        chosen_response = turn_data['chosen']  # ç”¨æˆ·é€‰æ‹©çš„å›å¤
        
        # æ„å»ºå†å²ï¼ˆåªåŒ…æ‹¬ chosen å›å¤ï¼‰
        history = build_history(turns[:turn_idx + 1])
        
        # æ­¥éª¤ 1: åˆå§‹åŒ–æˆ–ä¼ æ’­å‡è®¾
        if hypotheses is None:
            hypotheses = initialize_hypotheses(user_id, history, candidates)
        else:
            hypotheses = propagate_hypotheses(hypotheses, history, candidates)
        
        # æ­¥éª¤ 2: åŠ æƒå‡è®¾
        weight_results = weigh_hypotheses(hypotheses, chosen_response, candidates)
        hypotheses.update_weights(weight_results['weights'])
        hypotheses.weight_details = weight_results
        
        # æ­¥éª¤ 3: æ£€æŸ¥æ˜¯å¦éœ€è¦é‡é‡‡æ ·
        if n_hypotheses > 1:
            ess = compute_ess(hypotheses)
            if ess < n_hypotheses / 2:
                hypotheses = resample_hypotheses_with_other_info(hypotheses, ess)
        
        # æ­¥éª¤ 4: ç”Ÿæˆå½“å‰ç”¨æˆ·ç”»åƒ
        user_profile = summarize_hypotheses(hypotheses)
        
        # æ­¥éª¤ 5: è¯„ä¼°æ€§èƒ½
        gen_score = evaluate_generation(user_profile, history, 
                                       candidates, chosen_response)
        predicted_idx = predict_choice(user_profile, history, candidates)
        actual_idx = find_chosen_index(candidates)
        prediction_correct = (predicted_idx == actual_idx)
        
        # ä¿å­˜ç»“æœ
        turn_results.append({
            'turn': turn_idx,
            'user_profile': user_profile,
            'gen_score': gen_score,
            'prediction_correct': prediction_correct,
            'hypotheses': hypotheses.texts,
            'weights': hypotheses.weights.tolist()
        })
    
    return {
        'user_id': user_id,
        'turn_results': turn_results,
        'final_profile': turn_results[-1]['user_profile'] if turn_results else ""
    }
```

---

## ä½¿ç”¨æŒ‡å—

### 1. å¿«é€Ÿå¼€å§‹

```bash
# éªŒè¯ç¯å¢ƒ
python test_setup.py

# å°è§„æ¨¡æµ‹è¯•ï¼ˆ5 ç”¨æˆ·ï¼‰
python run_prism_pipeline.py --stage all --n-users 5 --run-id test

# æŸ¥çœ‹ç»“æœ
ls preference_results/
# preference_tracing_results_test.json
# preference_tracing_summary_test.json
# survey_evaluation_test.json
# plots/
```

### 2. ä½¿ç”¨é…ç½®æ–‡ä»¶

```bash
# å•ä¸ªå®éªŒ
python batch_runner.py --experiments quick_test

# æ¶ˆèå®éªŒ
python batch_runner.py --ablation-studies ablation_hypotheses

# è¿è¡Œæ‰€æœ‰
python batch_runner.py
```

### 3. è‡ªå®šä¹‰å®éªŒ

ç¼–è¾‘ `configs.yaml`:
```yaml
my_experiment:
  tracing_model: "gpt-4o-mini"
  eval_model: "gpt-4o-mini"
  n_hypotheses: 5
  n_users: 15
  output_dir: "results/my_exp"
  run_id: "my_exp_v1"
```

è¿è¡Œ:
```bash
python batch_runner.py --experiments my_experiment
```

---

## è¾“å‡ºè¯´æ˜

### preference_tracing_results_{run_id}.json

```json
[
  {
    "user_id": "u123",
    "turn_results": [
      {
        "turn": 0,
        "user_profile": "ç”¨æˆ·ç”»åƒæ–‡æœ¬",
        "gen_score": 0.85,
        "prediction_correct": true,
        "hypotheses": ["å‡è®¾1", "å‡è®¾2", "å‡è®¾3", "å‡è®¾4"],
        "weights": [0.4, 0.3, 0.2, 0.1]
      },
      {
        "turn": 1,
        ...
      }
    ],
    "final_profile": "æœ€ç»ˆç”¨æˆ·ç”»åƒ"
  },
  ...
]
```

### preference_tracing_summary_{run_id}.json

```json
{
  "turn_gen_scores": {
    "0": {"mean": 0.72, "std": 0.15, "ci": 0.08},
    "1": {"mean": 0.78, "std": 0.12, "ci": 0.06},
    ...
  },
  "turn_pred_accuracy": {
    "0": {"mean": 0.45, "std": 0.28, "ci": 0.14},
    "1": {"mean": 0.62, "std": 0.24, "ci": 0.12},
    ...
  }
}
```

### å¯è§†åŒ–

- `learning_curves.png`: åˆ†æ•°éšè½®æ¬¡å˜åŒ–ï¼ˆå¸¦ç½®ä¿¡åŒºé—´ï¼‰
- `user_trajectories.png`: ä¸ªä½“ç”¨æˆ·çš„å­¦ä¹ æ›²çº¿
- `survey_alignment.png`: ä¸é—®å·æ•°æ®çš„å¯¹é½ç¨‹åº¦

---

## æ€§èƒ½ä¸æˆæœ¬

### API è°ƒç”¨ä¼°ç®—

æ¯ä¸ªç”¨æˆ·ï¼Œæ¯è½®å¯¹è¯:
- Initialize: n_hypotheses æ¬¡è°ƒç”¨
- Propagate: n_hypotheses æ¬¡è°ƒç”¨
- Weigh: n_hypotheses æ¬¡è°ƒç”¨
- Summarize: 1 æ¬¡è°ƒç”¨
- Evaluate: 2 æ¬¡è°ƒç”¨

**æ€»è®¡**: çº¦ (3*n_hypotheses + 3) æ¬¡/è½®

ç¤ºä¾‹ (n_hypotheses=4, avg_turns=3):
- æ¯ç”¨æˆ·: ~45 æ¬¡è°ƒç”¨
- 20 ç”¨æˆ·: ~900 æ¬¡è°ƒç”¨
- gpt-4o-mini: ~$0.90
- gpt-4o: ~$9.00

### è¿è¡Œæ—¶é—´

- gpt-4o-mini: ~2-3 åˆ†é’Ÿ/ç”¨æˆ·
- gpt-4o: ~3-5 åˆ†é’Ÿ/ç”¨æˆ·
- 20 ç”¨æˆ·: ~40-100 åˆ†é’Ÿ

---

## æ‰©å±•ä¸æ”¹è¿›

### 1. è‡ªå®šä¹‰å‡è®¾ç”Ÿæˆ

```python
class CustomPreferenceTracer(PreferenceTracer):
    def initialize_hypotheses(self, user_id, history, candidates):
        # æ•´åˆç”¨æˆ·äººå£ç»Ÿè®¡ä¿¡æ¯
        user_demo = get_user_demographics(user_id)
        
        prompt = f"""
        User demographics: {user_demo}
        Conversation: {history}
        Candidates: {candidates}
        
        Generate hypotheses about user preferences considering their background.
        """
        # ...
```

### 2. ä¸»åŠ¨å­¦ä¹ 

```python
def select_informative_turns(self, all_turns):
    # é€‰æ‹©æœ€å…·ä¿¡æ¯é‡çš„è½®æ¬¡è¿›è¡Œå­¦ä¹ 
    # ä¾‹å¦‚ï¼šå€™é€‰å›å¤å·®å¼‚æœ€å¤§çš„è½®æ¬¡
    scores = [compute_candidate_diversity(turn) for turn in all_turns]
    return select_top_k(all_turns, scores, k=5)
```

### 3. å±‚æ¬¡åŒ–å‡è®¾

```python
# é¡¶å±‚ï¼šä»·å€¼è§‚
high_level_hypotheses = ["values accuracy", "values conciseness", ...]

# åº•å±‚ï¼šå…·ä½“åå¥½
for high_level in high_level_hypotheses:
    low_level_hypotheses = generate_specific_preferences(high_level)
```

---

## æ€»ç»“

âœ… **å·²å®ç°**:
- å®Œæ•´çš„åå¥½è¿½è¸ªæµç¨‹
- å¤šå‡è®¾ç²’å­æ»¤æ³¢
- åœ¨çº¿å­¦ä¹ ä¸è¯„ä¼°
- å¯è§†åŒ–ä¸åˆ†æ
- æ‰¹é‡å®éªŒæ”¯æŒ

âœ… **ä¼˜åŠ¿**:
- æ— éœ€æ ‡æ³¨çš„åå¥½æ•°æ®
- å¯è§£é‡Šçš„åå¥½æ¼”åŒ–
- ä¸ç¡®å®šæ€§é‡åŒ–
- æ¨¡å—åŒ–æ˜“æ‰©å±•

ğŸ“Š **åº”ç”¨**:
- ä¸ªæ€§åŒ–å¯¹è¯ç³»ç»Ÿ
- ç”¨æˆ·ç”»åƒæ„å»º
- åå¥½å¯¹é½ç ”ç©¶
- A/B æµ‹è¯•ä¼˜åŒ–

ğŸš€ **ä¸‹ä¸€æ­¥**:
1. è¿è¡Œæ¶ˆèå®éªŒ
2. åˆ†æä¸åŒç”¨æˆ·ç±»å‹
3. ä¼˜åŒ–æç¤ºå·¥ç¨‹
4. æ¢ç´¢ä¸»åŠ¨å­¦ä¹ ç­–ç•¥
